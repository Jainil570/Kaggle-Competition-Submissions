{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94521,"databundleVersionId":11239181,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\n\ntry:\n    from supplemental_english import REGION_CODES, GOVERNMENT_CODES\nexcept ImportError:\n    REGION_CODES = {}\n    GOVERNMENT_CODES = {}\n\ndef parse_date(date_str):\n    if pd.isnull(date_str):\n        return np.nan\n    if ' - ' in date_str:\n        date_str = date_str.split(' - ')[0].strip()\n    try:\n        return pd.to_datetime(date_str, errors='coerce')\n    except Exception:\n        return np.nan\n\ndef extract_plate_features(plate):\n    features = {}\n    m = re.search(r'(\\d{2,3})$', plate)\n    features['region'] = m.group(1) if m else np.nan\n    \n    digit_groups = re.findall(r'\\d+', plate)\n    if len(digit_groups) >= 1:\n        features['number_part'] = digit_groups[0]\n    else:\n        features['number_part'] = np.nan\n\n    letters = re.sub(r'\\d+', '', plate)\n    features['letters'] = letters\n    features['plate_length'] = len(plate)\n    return features\n\ndef check_government_code(letters, number_str, region):\n    try:\n        number_val = int(number_str)\n    except:\n        return (0, 0, 0)\n    for (letters_key, (num_min, num_max), region_key), info in GOVERNMENT_CODES.items():\n        if letters_key == letters and region_key == region:\n            if num_min <= number_val <= num_max:\n                _, is_forbidden, has_advantage, significance = info\n                return (is_forbidden, has_advantage, significance)\n    return (0, 0, 0)\n\ndef smape(y_true, y_pred):\n    numerator = np.abs(y_true - y_pred)\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n    return np.mean(np.where(denominator == 0, 0, numerator / denominator)) * 100\n\ntrain = pd.read_csv('/kaggle/input/russian-car-plates-prices-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/russian-car-plates-prices-prediction/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/russian-car-plates-prices-prediction/sample_submission.csv')\n\nreference_date = pd.to_datetime(\"2021-01-01\")\n\nfor df in [train, test]:\n    df['parsed_date'] = df['date'].apply(parse_date)\n    df['year'] = df['parsed_date'].dt.year\n    df['month'] = df['parsed_date'].dt.month\n    df['day'] = df['parsed_date'].dt.day\n    df['weekday'] = df['parsed_date'].dt.weekday\n    df['days_since_2021'] = (df['parsed_date'] - reference_date).dt.days\n\ndef add_plate_features(df):\n    plate_feats = df['plate'].apply(extract_plate_features)\n    plate_df = pd.DataFrame(list(plate_feats))\n\n    gov_features = plate_df.apply(\n        lambda row: check_government_code(row['letters'], row['number_part'], row['region']),\n        axis=1\n    )\n    plate_df[['is_forbidden','has_advantage','significance_level']] = pd.DataFrame(gov_features.tolist(), index=plate_df.index)\n    \n    plate_df['number_part'] = pd.to_numeric(plate_df['number_part'], errors='coerce')\n    df = pd.concat([df, plate_df], axis=1)\n    return df\n\ntrain = add_plate_features(train)\ntest = add_plate_features(test)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfor col in ['region', 'letters']:\n    le = LabelEncoder()\n    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n    le.fit(combined)\n    train[col + '_enc'] = le.transform(train[col].astype(str))\n    test[col + '_enc'] = le.transform(test[col].astype(str))\n\nprice_cap = train['price'].quantile(0.995)\ntrain['price'] = np.where(train['price'] > price_cap, price_cap, train['price'])\ntrain['price_log'] = np.log1p(train['price'])\n\nfeatures = [\n    'days_since_2021',\n    'weekday',\n    'plate_length',\n    'number_part',\n    'region_enc',\n    'letters_enc',\n    'is_forbidden',\n    'has_advantage',\n    'significance_level'\n]\nX = train[features]\ny_log = train['price_log']\nX_test = test[features]\n\ncutoff_date = pd.to_datetime('2024-07-01')\ntrain_mask = train['parsed_date'] < cutoff_date\nvalid_mask = train['parsed_date'] >= cutoff_date\n\nX_train = X[train_mask]\ny_train = y_log[train_mask]\nX_valid = X[valid_mask]\ny_valid = y_log[valid_mask]\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_valid = lgb.Dataset(X_valid, y_valid)\n\nparams = {\n    'objective': 'regression',\n    'metric': 'mae',\n    'verbosity': -1,\n    'seed': 42\n}\n\ncallbacks = [\n    lgb.early_stopping(stopping_rounds=50),\n    lgb.log_evaluation(period=50)\n]\n\nmodel = lgb.train(\n    params,\n    train_set=lgb_train,\n    num_boost_round=1000,\n    valid_sets=[lgb_valid],\n    callbacks=callbacks\n)\n\ny_valid_pred_log = model.predict(X_valid, num_iteration=model.best_iteration)\ny_valid_pred = np.expm1(y_valid_pred_log)\ny_valid_true = np.expm1(y_valid)  \n\nval_smape = smape(y_valid_true.values, y_valid_pred)\nprint(f\"Validation SMAPE (time-based split): {val_smape:.4f}%\")\n\nfull_train = lgb.Dataset(X, y_log)\nmodel_full = lgb.train(params, full_train, num_boost_round=model.best_iteration)\n\ntest_pred_log = model_full.predict(X_test)\ntest_pred = np.expm1(test_pred_log)\n\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'price': test_pred\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created with time-based split (no lag features)!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T15:00:50.204098Z","iopub.execute_input":"2025-03-02T15:00:50.204463Z","iopub.status.idle":"2025-03-02T15:01:31.776860Z","shell.execute_reply.started":"2025-03-02T15:00:50.204434Z","shell.execute_reply":"2025-03-02T15:01:31.775624Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 50 rounds\n[50]\tvalid_0's l1: 0.623546\n[100]\tvalid_0's l1: 0.573657\n[150]\tvalid_0's l1: 0.563555\n[200]\tvalid_0's l1: 0.567905\nEarly stopping, best iteration is:\n[163]\tvalid_0's l1: 0.560082\nValidation SMAPE (time-based split): 51.3600%\nSubmission file created with time-based split (no lag features)!\n","output_type":"stream"}],"execution_count":2}]}