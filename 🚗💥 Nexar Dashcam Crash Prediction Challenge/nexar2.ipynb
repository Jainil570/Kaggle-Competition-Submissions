{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92399,"databundleVersionId":11038207,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Install Essential Libraries\n!pip install pytorchvideo timm scikit-learn -q\n\n# Step 2: Imports\nimport torch\nimport torch.nn as nn\nimport pytorchvideo.models.resnet as video_resnet\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\n\n# Step 3: Dataset Class\nclass CollisionDataset(Dataset):\n    def __init__(self, df, video_dir, num_frames=16):\n        self.df = df\n        self.video_dir = video_dir\n        self.num_frames = num_frames\n        self.transform = A.Compose([\n            A.Resize(256, 256),\n            A.RandomCrop(224, 224),\n            A.HorizontalFlip(p=0.5),\n        ])\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        video_path = f\"{self.video_dir}/{row['id']}.mp4\"\n        \n        # Capture frames\n        cap = cv2.VideoCapture(video_path)\n        frames = []\n        for _ in range(self.num_frames):\n            ret, frame = cap.read()\n            if ret:\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                frame = self.transform(image=frame)['image']\n                frames.append(frame)\n        cap.release()\n        \n        # Pad if needed\n        while len(frames) < self.num_frames:\n            frames.append(np.zeros((224,224,3), dtype=np.uint8))\n            \n        return torch.tensor(np.array(frames)).permute(3,0,1,2).float(), torch.tensor(row['target'])\n\n# Step 4: Simple Model (ResNet50)\nclass CollisionPredictor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = video_resnet.create_resnet(\n            input_channel=3,\n            model_depth=50,  # Correct depth\n            model_num_class=1,\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        return self.sigmoid(self.model(x))\n\n# Rest of the code remains same as last working version\n# ... [Training loop, inference, etc] ...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:55:23.570701Z","iopub.execute_input":"2025-02-26T19:55:23.571177Z","iopub.status.idle":"2025-02-26T19:55:27.153183Z","shell.execute_reply.started":"2025-02-26T19:55:23.571144Z","shell.execute_reply":"2025-02-26T19:55:27.151456Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CollisionPredictor().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.BCELoss()\n\n# Step 6: Data Loading\n\n# Step 7: Training Loop\n\n# Step 8: Inference\n\n# Step 9: Generate Submission\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:57:59.211798Z","iopub.execute_input":"2025-02-26T19:57:59.212130Z","iopub.status.idle":"2025-02-26T19:57:59.632539Z","shell.execute_reply.started":"2025-02-26T19:57:59.212103Z","shell.execute_reply":"2025-02-26T19:57:59.631153Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nexar-collision-prediction/train.csv\")\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n\ntrain_loader = DataLoader(\n    CollisionDataset(train_df, \"/kaggle/input/nexar-collision-prediction/train\"),\n    batch_size=8,\n    shuffle=True,\n    num_workers=2\n)\n\nval_loader = DataLoader(\n    CollisionDataset(val_df, \"/kaggle/input/nexar-collision-prediction/train\"),\n    batch_size=8,\n    num_workers=2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:58:03.288730Z","iopub.execute_input":"2025-02-26T19:58:03.289090Z","iopub.status.idle":"2025-02-26T19:58:03.306768Z","shell.execute_reply.started":"2025-02-26T19:58:03.289065Z","shell.execute_reply":"2025-02-26T19:58:03.305369Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Modify the dataset class to ensure float32 dtype\nclass CollisionDataset(Dataset):\n    def __init__(self, df, video_dir, num_frames=16):\n        self.df = df\n        self.video_dir = video_dir\n        self.num_frames = num_frames\n        self.transform = A.Compose([\n            A.Resize(256, 256),\n            A.RandomCrop(224, 224),\n            A.HorizontalFlip(p=0.5),\n        ])\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        video_path = f\"{self.video_dir}/{row['id']}.mp4\"\n        \n        # Capture frames\n        cap = cv2.VideoCapture(video_path)\n        frames = []\n        for _ in range(self.num_frames):\n            ret, frame = cap.read()\n            if ret:\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                frame = self.transform(image=frame)['image']\n                frames.append(frame)\n        cap.release()\n        \n        # Pad if needed and convert to float32\n        while len(frames) < self.num_frames:\n            frames.append(np.zeros((224,224,3), dtype=np.uint8))\n            \n        # Convert to float32 explicitly\n        frames_tensor = torch.tensor(np.array(frames), dtype=torch.float32).permute(3,0,1,2)\n        label_tensor = torch.tensor(row['target'], dtype=torch.float32)  # Fix here\n        return frames_tensor, label_tensor\n\n# Modify the training loop to ensure dtype consistency\nfor epoch in range(2):\n    model.train()\n    for frames, labels in train_loader:\n        # Convert to float32 if needed (should already be done by dataset)\n        frames = frames.to(device, dtype=torch.float32)\n        labels = labels.to(device, dtype=torch.float32)\n        \n        optimizer.zero_grad()\n        outputs = model(frames).squeeze()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # Validation (same dtype conversion)\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for frames, labels in val_loader:\n            frames = frames.to(device, dtype=torch.float32)\n            labels = labels.to(device, dtype=torch.float32)\n            outputs = model(frames).squeeze()\n            val_loss += criterion(outputs, labels).item()\n    print(f\"Epoch {epoch+1} | Val Loss: {val_loss/len(val_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T20:01:13.329332Z","iopub.execute_input":"2025-02-26T20:01:13.329841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef predict_video(video_path):\n    model.eval()\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    try:\n        while len(frames) < 16:\n            ret, frame = cap.read()\n            if not ret: break\n            frame = cv2.resize(frame, (224,224))\n            frames.append(frame)\n            if len(frames) == 16:\n                inputs = torch.tensor(frames).permute(3,0,1,2).unsqueeze(0).float().to(device)\n                pred = model(inputs).item()\n                if pred > 0.5:  # Early exit\n                    return pred\n                frames = frames[8:]  # 50% overlap\n    finally:\n        cap.release()\n    return pred if len(frames) >=8 else 0.0  # Edge case\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/nexar-collision-prediction/test.csv\")\nscores = [predict_video(f\"/kaggle/input/nexar-collision-prediction/test/{vid}.mp4\") for vid in test_df['id']]\npd.DataFrame({'id': test_df['id'], 'score': scores}).to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}