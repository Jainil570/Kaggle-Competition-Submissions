{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:29:57.591238Z","iopub.execute_input":"2025-02-09T12:29:57.591616Z","iopub.status.idle":"2025-02-09T12:29:57.602208Z","shell.execute_reply.started":"2025-02-09T12:29:57.591580Z","shell.execute_reply":"2025-02-09T12:29:57.600909Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load Data\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s5e2/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e2/test.csv')\nextra_train_df = pd.read_csv('/kaggle/input/playground-series-s5e2/training_extra.csv')\n\n# Fill categorical missing values with mode from train_df\ncategorical_cols = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\nfor col in categorical_cols:\n    mode_value = train_df[col].mode()[0]  \n    train_df[col].fillna(mode_value, inplace=True)\n    test_df[col].fillna(mode_value, inplace=True)\n    extra_train_df[col].fillna(mode_value, inplace=True)\n\n# Fill numerical missing values with median\nnumerical_cols = ['Weight Capacity (kg)', 'Compartments']\nfor col in numerical_cols:\n    train_df[col].fillna(train_df[col].median(), inplace=True)\n    test_df[col].fillna(test_df[col].median(), inplace=True)\n    extra_train_df[col].fillna(extra_train_df[col].median(), inplace=True)\n\n# Create a new feature combining 'Material' and 'Size'\ntrain_df['Material_Size'] = train_df['Material'] + \"_\" + train_df['Size']\ntest_df['Material_Size'] = test_df['Material'] + \"_\" + test_df['Size']\nextra_train_df['Material_Size'] = extra_train_df['Material'] + \"_\" + extra_train_df['Size']\n\n# Convert 'Laptop Compartment' to numeric (1 if 'Yes', 0 otherwise)\ntrain_df['Laptop Compartment'] = train_df['Laptop Compartment'].apply(lambda x: 1 if x == \"Yes\" else 0)\ntest_df['Laptop Compartment'] = test_df['Laptop Compartment'].apply(lambda x: 1 if x == \"Yes\" else 0)\nextra_train_df['Laptop Compartment'] = extra_train_df['Laptop Compartment'].apply(lambda x: 1 if x == \"Yes\" else 0)\n\n# Merge 'Compartments' and 'Laptop Compartment' into 'Total_Compartments'\ntrain_df['Total_Compartments'] = train_df['Compartments'] + train_df['Laptop Compartment']\ntest_df['Total_Compartments'] = test_df['Compartments'] + test_df['Laptop Compartment']\nextra_train_df['Total_Compartments'] = extra_train_df['Compartments'] + extra_train_df['Laptop Compartment']\n\n# Encode categorical features using train_df's encoding\ncategorical_features = ['Brand', 'Material_Size', 'Waterproof', 'Style', 'Color']\nencoder = LabelEncoder()\n\nfor col in categorical_features:\n    train_df[col] = encoder.fit_transform(train_df[col])  \n    test_df[col] = encoder.transform(test_df[col])        \n    extra_train_df[col] = encoder.transform(extra_train_df[col])\n\n# Drop merged columns\ntrain_df.drop(columns=['Material', 'Size', 'Compartments', 'Laptop Compartment'], inplace=True)\ntest_df.drop(columns=['Material', 'Size', 'Compartments', 'Laptop Compartment'], inplace=True)\nextra_train_df.drop(columns=['Material', 'Size', 'Compartments', 'Laptop Compartment'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:29:57.603892Z","iopub.execute_input":"2025-02-09T12:29:57.604259Z","iopub.status.idle":"2025-02-09T12:30:12.472638Z","shell.execute_reply.started":"2025-02-09T12:29:57.604218Z","shell.execute_reply":"2025-02-09T12:30:12.471348Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-23-ca00438b81ba>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_df[col].fillna(mode_value, inplace=True)\n<ipython-input-23-ca00438b81ba>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df[col].fillna(mode_value, inplace=True)\n<ipython-input-23-ca00438b81ba>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  extra_train_df[col].fillna(mode_value, inplace=True)\n<ipython-input-23-ca00438b81ba>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_df[col].fillna(train_df[col].median(), inplace=True)\n<ipython-input-23-ca00438b81ba>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df[col].fillna(test_df[col].median(), inplace=True)\n<ipython-input-23-ca00438b81ba>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  extra_train_df[col].fillna(extra_train_df[col].median(), inplace=True)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Merge the extra training data with the main training data\ntrain_df = pd.concat([train_df, extra_train_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:30:12.474878Z","iopub.execute_input":"2025-02-09T12:30:12.475354Z","iopub.status.idle":"2025-02-09T12:30:12.572838Z","shell.execute_reply.started":"2025-02-09T12:30:12.475309Z","shell.execute_reply":"2025-02-09T12:30:12.571684Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize scaler\nscaler = StandardScaler()\n\n# Apply scaling\ntrain_df['Weight Capacity (kg)'] = scaler.fit_transform(train_df[['Weight Capacity (kg)']])\ntest_df['Weight Capacity (kg)'] = scaler.transform(test_df[['Weight Capacity (kg)']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:30:12.574447Z","iopub.execute_input":"2025-02-09T12:30:12.574764Z","iopub.status.idle":"2025-02-09T12:30:12.658511Z","shell.execute_reply.started":"2025-02-09T12:30:12.574735Z","shell.execute_reply":"2025-02-09T12:30:12.657494Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define features and target\nX = train_df.drop(columns=['Price'])  # Replace 'Target' with your actual target column name\ny = train_df['Price']\n\n# Split data into training and validation sets (80-20 split)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:30:12.659733Z","iopub.execute_input":"2025-02-09T12:30:12.660136Z","iopub.status.idle":"2025-02-09T12:30:16.614836Z","shell.execute_reply.started":"2025-02-09T12:30:12.660098Z","shell.execute_reply":"2025-02-09T12:30:16.613805Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Best parameters (based on common optimizations)\nrf_model = RandomForestRegressor(\n    n_estimators=100,   # Balanced between speed & accuracy\n    max_depth=20,       # Prevents overfitting\n    min_samples_split=5, # Better generalization\n    random_state=42,\n    n_jobs=-1           # Use all CPU cores\n)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Predictions\ny_pred = rf_model.predict(X_test)\n\n# Evaluation\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"Mean Absolute Error:\", mae)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T12:30:21.037684Z","iopub.execute_input":"2025-02-09T12:30:21.038104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params = grid_search.best_params_\n\n# Train the final model with best parameters\nfinal_model = RandomForestRegressor(**best_params, random_state=42)\nfinal_model.fit(X_train, y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nimport numpy as np\n\n# Predict on validation set\ny_val_pred = final_model.predict(X_val)\n\n# Evaluate performance\nmae = mean_absolute_error(y_val, y_val_pred)\nrmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n\nprint(f\"Validation MAE: {mae}\")\nprint(f\"Validation RMSE: {rmse}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on test data\ntest_predictions = final_model.predict(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission dataframe\nsubmission = pd.DataFrame({\n    'Id': test_df['Id'],  # Make sure 'Id' column exists in test data\n    'Weight Capacity (kg)': test_predictions\n})\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file saved as 'submission.csv'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}